{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransNet: A deep network for fast detection of common shot transitions\n",
    "This repository contains code for paper *TransNet: A deep network for fast detection of common shot transitions*.\n",
    "\n",
    "If you use it in your work, please cite:\n",
    "\n",
    "\n",
    "    @article{soucek2019transnet,\n",
    "        title={TransNet: A deep network for fast detection of common shot transitions},\n",
    "        author={Sou{\\v{c}}ek, Tom{\\'a}{\\v{s}} and Moravec, Jaroslav and Loko{\\v{c}}, Jakub},\n",
    "        journal={arXiv preprint arXiv:1906.03363},\n",
    "        year={2019}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use it?\n",
    "\n",
    "Firstly, *tensorflow* needs to be installed.\n",
    "Do so by doing:\n",
    "\n",
    "    pip install tensorflow\n",
    "\n",
    "If you want to run **TransNet** directly on video files, *ffmpeg* needs to be installed as well:\n",
    "\n",
    "    pip install ffmpeg-python\n",
    "\n",
    "You can also install *pillow* for visualization:\n",
    "\n",
    "    pip install pillow\n",
    "\n",
    "    \n",
    "Tested with *tensorflow* v1.12.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install ffmpeg-python\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from transnet import TransNetParams, TransNet\n",
    "from transnet_utils import draw_video_with_predictions, scenes_from_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "params = TransNetParams()\n",
    "params.CHECKPOINT_PATH = \"./model/transnet_model-F16_L3_S2_D256\"\n",
    "\n",
    "net = TransNet(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export video into numpy array using ffmpeg\n",
    "video_stream, err = (\n",
    "    ffmpeg\n",
    "    .input('test.mp4')\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(params.INPUT_WIDTH, params.INPUT_HEIGHT))\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "video = np.frombuffer(video_stream, np.uint8).reshape([-1, params.INPUT_HEIGHT, params.INPUT_WIDTH, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict transitions using the neural network\n",
    "predictions = net.predict_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot all 64 maps in an 8x8 squares\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# for i in range(544):\n",
    "#     square = 16\n",
    "#     ix = 1\n",
    "#     for _ in range(square):\n",
    "#         for _ in range(square):\n",
    "#             # specify subplot and turn of axis\n",
    "#             ax = plt.subplot(square, square, ix)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             # plot filter channel in grayscale\n",
    "#             plt.imshow(predictions[i, :, :, ix-1])\n",
    "#             #plt.imshow(predictions[0, :, :, ix-1])\n",
    "#             ix += 1\n",
    "#     # show the figure\n",
    "#     plt.show()\n",
    "    \n",
    "square = 16\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "            # specify subplot and turn of axis\n",
    "            ax = plt.subplot(square, square, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            plt.imshow(predictions[i, :, :, ix-1])\n",
    "            #plt.imshow(predictions[0, :, :, ix-1])\n",
    "            ix += 1\n",
    "    # show the figure\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.plot(predictions, marker='o', linestyle='--')\n",
    "# #plt.xlim(0,100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "Function `draw_video_with_predictions` displays all video frames with confidence bars for each frame. The green bar is considered as detected shot boundary (predicted value exceeds the threshold), the red bar is shown otherwise.\n",
    "\n",
    "Function `scenes_from_predictions` returns a list of scenes for a given video. Each scene is defined as a tuple of (start frame, end frame).\n",
    "\n",
    "As described in the paper, the threshold of `0.1` is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # For ilustration purposes, we show only 200 frames starting with frame number 8000.\n",
    "# draw_video_with_predictions(video[:], predictions[:], threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Generate list of scenes from predictions, returns tuples of (start frame, end frame)\n",
    "# scenes = scenes_from_predictions(predictions, threshold=0.1)\n",
    "\n",
    "# # For ilustration purposes, only the visualized scenes are shown.\n",
    "# scenes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
